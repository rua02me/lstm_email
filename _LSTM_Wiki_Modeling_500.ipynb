{"cells":[{"cell_type":"code","execution_count":1,"id":"4432b677","metadata":{"id":"4432b677","executionInfo":{"status":"ok","timestamp":1668126089972,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"outputs":[],"source":["# Set up IPython to show all outputs from a cell\n","import warnings\n","from IPython.core.interactiveshell import InteractiveShell\n","\n","InteractiveShell.ast_node_interactivity = 'all'\n","\n","warnings.filterwarnings('ignore', category=RuntimeWarning)\n","\n","RANDOM_STATE = 50\n","EPOCHS = 150\n","BATCH_SIZE = 2048\n","TRAINING_LENGTH = 50\n","TRAIN_FRACTION = 0.7\n","LSTM_CELLS = 64\n","VERBOSE = 0\n","SAVE_MODEL = True"]},{"cell_type":"code","execution_count":2,"id":"0d633f44","metadata":{"id":"0d633f44","executionInfo":{"status":"ok","timestamp":1668126091359,"user_tz":300,"elapsed":1391,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n"]},{"cell_type":"code","source":["# import raw data\n","data = pd.read_csv('https://raw.githubusercontent.com/Jessica-ngce/lstm_wiki_data/main/wikiArticle_summary500.csv')\n","data.info()"],"metadata":{"id":"N8Ztbkg6SXrS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668126091895,"user_tz":300,"elapsed":543,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"outputId":"7a32f35f-b549-4d38-84a5-efba9eff532c"},"id":"N8Ztbkg6SXrS","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 500 entries, 0 to 499\n","Data columns (total 2 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   Unnamed: 0  500 non-null    int64 \n"," 1   0           500 non-null    object\n","dtypes: int64(1), object(1)\n","memory usage: 7.9+ KB\n"]}]},{"cell_type":"code","execution_count":4,"id":"ba1c6e4d","metadata":{"id":"ba1c6e4d","executionInfo":{"status":"ok","timestamp":1668126091896,"user_tz":300,"elapsed":24,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"colab":{"base_uri":"https://localhost:8080/","height":419},"outputId":"d2ebcb4c-f134-4888-e6ba-000a62abbd0c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Unnamed: 0                                                  0\n","0             0  Euchalcia maria is a moth of the family Noctui...\n","1             1  The Siøsund Bridge (Danish: Siøsundbroen) is a...\n","2             2  In chemistry, dialysis is the process of separ...\n","3             3  The Crestar-Farm Fresh Classic was a golf tour...\n","4             4  The 2005 Men's South American Volleyball Champ...\n","..          ...                                                ...\n","495         495  Eight ships of the Royal Navy have borne the n...\n","496         496  Beauty Has Grace is the Christian singer Jaci ...\n","497         497  Michael Steward Heath (born April 9, 1964) is ...\n","498         498  Golakhvor (Persian: گل اخور, also Romanized as...\n","499         499  The 2015 Asian Archery Championships were the ...\n","\n","[500 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-539ae064-4c85-47ce-a068-c170641b3b18\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Euchalcia maria is a moth of the family Noctui...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>The Siøsund Bridge (Danish: Siøsundbroen) is a...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>In chemistry, dialysis is the process of separ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>The Crestar-Farm Fresh Classic was a golf tour...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>The 2005 Men's South American Volleyball Champ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>495</th>\n","      <td>495</td>\n","      <td>Eight ships of the Royal Navy have borne the n...</td>\n","    </tr>\n","    <tr>\n","      <th>496</th>\n","      <td>496</td>\n","      <td>Beauty Has Grace is the Christian singer Jaci ...</td>\n","    </tr>\n","    <tr>\n","      <th>497</th>\n","      <td>497</td>\n","      <td>Michael Steward Heath (born April 9, 1964) is ...</td>\n","    </tr>\n","    <tr>\n","      <th>498</th>\n","      <td>498</td>\n","      <td>Golakhvor (Persian: گل اخور, also Romanized as...</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>499</td>\n","      <td>The 2015 Asian Archery Championships were the ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>500 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-539ae064-4c85-47ce-a068-c170641b3b18')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-539ae064-4c85-47ce-a068-c170641b3b18 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-539ae064-4c85-47ce-a068-c170641b3b18');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["data"]},{"cell_type":"code","execution_count":5,"id":"735a5f7c","metadata":{"id":"735a5f7c","executionInfo":{"status":"ok","timestamp":1668126091896,"user_tz":300,"elapsed":19,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"17dc7132-d102-4dd0-e138-a09bcd931298"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["500"]},"metadata":{},"execution_count":5}],"source":["# Extract body\n","original_abstracts = list(data['0'])\n","len(original_abstracts)\n"]},{"cell_type":"code","execution_count":6,"id":"7ef0c4db","metadata":{"id":"7ef0c4db","executionInfo":{"status":"ok","timestamp":1668126091897,"user_tz":300,"elapsed":14,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"outputs":[],"source":["import re\n","\n","def format_patent(patent):\n","    \"\"\"Add spaces around punctuation and remove references to images/citations.\"\"\"\n","\n","    # Add spaces around punctuation\n","    patent = re.sub(r'(?<=[^\\s0-9])(?=[.,;?])', r' ', patent)\n","\n","    # Remove references to figures\n","    patent = re.sub(r'\\((\\d+)\\)', r'', patent)\n","\n","    # Remove all website links\n","    # patent = re.sub(r'http\\S+', r'', patent)\n","    patent = re.sub('http[s]?://\\S+', r'', patent)\n","    \n","    # Remove double spaces\n","    patent = re.sub(r'\\s\\s', ' ', patent)\n","\n","\n","    return patent\n"]},{"cell_type":"code","execution_count":7,"id":"01ffebe3","metadata":{"id":"01ffebe3","executionInfo":{"status":"ok","timestamp":1668126091897,"user_tz":300,"elapsed":13,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"30320103-9f5a-4b8a-aa22-a8e9301136c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["500"]},"metadata":{},"execution_count":7}],"source":["formatted = []\n","\n","# Iterate through all the original abstracts\n","for a in original_abstracts:\n","    formatted.append(format_patent(a))\n","\n","len(formatted)"]},{"cell_type":"code","execution_count":8,"id":"93a66ccb","metadata":{"id":"93a66ccb","executionInfo":{"status":"ok","timestamp":1668126098468,"user_tz":300,"elapsed":6579,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"outputs":[],"source":["import keras"]},{"cell_type":"code","execution_count":9,"id":"22ebb097","metadata":{"id":"22ebb097","executionInfo":{"status":"ok","timestamp":1668126098468,"user_tz":300,"elapsed":8,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"outputs":[],"source":["from keras.preprocessing.text import Tokenizer"]},{"cell_type":"code","execution_count":10,"id":"30aa1d31","metadata":{"id":"30aa1d31","executionInfo":{"status":"ok","timestamp":1668126098469,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"outputs":[],"source":["# Convert Text to Sequences\n","\n","def make_sequences(texts,\n","                   training_length=50,\n","                   lower=True,\n","                   filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'):\n","    \"\"\"Turn a set of texts into sequences of integers\"\"\"\n","\n","    # Create the tokenizer object and train on texts\n","    tokenizer = Tokenizer(lower=lower, filters=filters)\n","    tokenizer.fit_on_texts(texts)\n","\n","    # Create look-up dictionaries and reverse look-ups\n","    word_idx = tokenizer.word_index\n","    idx_word = tokenizer.index_word\n","    num_words = len(word_idx) + 1\n","    word_counts = tokenizer.word_counts\n","\n","    print(f'There are {num_words} unique words.')\n","\n","    # Convert text to sequences of integers\n","    sequences = tokenizer.texts_to_sequences(texts)\n","\n","    # Limit to sequences with more than training length tokens\n","    seq_lengths = [len(x) for x in sequences]\n","    over_idx = [\n","        i for i, l in enumerate(seq_lengths) if l > (training_length + 20)\n","    ]\n","\n","    new_texts = []\n","    new_sequences = []\n","\n","    # Only keep sequences with more than training length tokens\n","    for i in over_idx:\n","        new_texts.append(texts[i])\n","        new_sequences.append(sequences[i])\n","\n","    training_seq = []\n","    labels = []\n","\n","    # Iterate through the sequences of tokens\n","    for seq in new_sequences:\n","\n","        # Create multiple training examples from each sequence\n","        for i in range(training_length, len(seq)):\n","            # Extract the features and label\n","            extract = seq[i - training_length:i + 1]\n","\n","            # Set the features and label\n","            training_seq.append(extract[:-1])\n","            labels.append(extract[-1])\n","\n","    print(f'There are {len(training_seq)} training sequences.')\n","\n","    # Return everything needed for setting up the model\n","    return word_idx, idx_word, num_words, word_counts, new_texts, new_sequences, training_seq, labels\n"]},{"cell_type":"code","execution_count":11,"id":"9c54ec20","metadata":{"id":"9c54ec20","executionInfo":{"status":"ok","timestamp":1668126098931,"user_tz":300,"elapsed":468,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"304adee7-9f45-4a83-82f3-81491668f184"},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 10047 unique words.\n","There are 23652 training sequences.\n"]}],"source":["TRAINING_LEGNTH = 50\n","filters = '!\"#$%&()*+/:<=>@[\\\\]^_`{|}~\\t\\n'\n","word_idx, idx_word, num_words, word_counts, abstracts, sequences, features, labels = make_sequences(\n","    formatted, 50, lower=True, filters=filters)"]},{"cell_type":"code","source":["n = 3\n","features[n][:10]"],"metadata":{"id":"v44149AkTMhk","executionInfo":{"status":"ok","timestamp":1668126098931,"user_tz":300,"elapsed":28,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ecd5fcb8-204c-484c-8d9f-274eef5c7ad6"},"id":"v44149AkTMhk","execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[499, 3858, 8, 7, 188, 432, 21, 1222, 1, 499]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["def find_answer(index):\n","    \"\"\"Find label corresponding to features for index in training data\"\"\"\n","\n","    # Find features and label\n","    feats = ' '.join(idx_word[i] for i in features[index])\n","    answer = idx_word[labels[index]]\n","\n","    print('Features:', feats)\n","    print('\\nLabel: ', answer)"],"metadata":{"id":"DA2EOfWATPzf","executionInfo":{"status":"ok","timestamp":1668126098932,"user_tz":300,"elapsed":22,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"DA2EOfWATPzf","execution_count":13,"outputs":[]},{"cell_type":"code","source":["find_answer(n)"],"metadata":{"id":"j6ap5Qp4TU1K","executionInfo":{"status":"ok","timestamp":1668126098932,"user_tz":300,"elapsed":21,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d93e1ced-99a4-4fef-a343-802406e25021"},"id":"j6ap5Qp4TU1K","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Features: danish siøsundbroen is a road bridge that connects the danish islands of tåsinge and siø . it crosses siøsund , a shallow strait that allowed much of the link to be built as a causeway , the siø causeway or siø dam danish siødæmningen .the bridge is a low box\n","\n","Label:  girder\n"]}]},{"cell_type":"code","source":["original_abstracts[0]"],"metadata":{"id":"fj4p9kBZTV_V","executionInfo":{"status":"ok","timestamp":1668126098932,"user_tz":300,"elapsed":17,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"4ed4af85-15a2-438a-e233-3cc752946f0c"},"id":"fj4p9kBZTV_V","execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Euchalcia maria is a moth of the family Noctuidae. It is endemic of the Levant. It is found from south-eastern Turkey to Israel.\\nAdults are on wing from March to May. There is one generation per year.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["find_answer(100)"],"metadata":{"id":"Azzoqid3TmXE","executionInfo":{"status":"ok","timestamp":1668126098932,"user_tz":300,"elapsed":15,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"75da10df-ba5a-45f4-f770-0202d7678ec6"},"id":"Azzoqid3TmXE","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Features: separating molecules in solution by the difference in their rates of diffusion through a semipermeable membrane , such as dialysis tubing .dialysis is a common laboratory technique that operates on the same principle as medical dialysis . in the context of life science research , the most common application of\n","\n","Label:  dialysis\n"]}]},{"cell_type":"code","source":["sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:15]"],"metadata":{"id":"d330v3mxTzbx","executionInfo":{"status":"ok","timestamp":1668126098933,"user_tz":300,"elapsed":11,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0b57f96-70cc-412a-ac91-efd94dd6fdec"},"id":"d330v3mxTzbx","execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('the', 2825),\n"," (',', 2229),\n"," ('.', 1858),\n"," ('of', 1486),\n"," ('in', 1224),\n"," ('and', 1196),\n"," ('a', 1015),\n"," ('is', 762),\n"," ('was', 583),\n"," ('to', 552),\n"," ('as', 346),\n"," ('by', 308),\n"," ('on', 307),\n"," ('for', 283),\n"," ('it', 281)]"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# Training Data\n"],"metadata":{"id":"Flb1VkZoW5eq"},"id":"Flb1VkZoW5eq"},{"cell_type":"code","source":["# Encoding of Labels\n","from sklearn.utils import shuffle\n","\n","\n","def create_train_valid(features,\n","                       labels,\n","                       num_words,\n","                       train_fraction=TRAIN_FRACTION):\n","    \"\"\"Create training and validation features and labels.\"\"\"\n","\n","    # Randomly shuffle features and labels\n","    features, labels = shuffle(features, labels, random_state=RANDOM_STATE)\n","\n","    # Decide on number of samples for training\n","    train_end = int(train_fraction * len(labels))\n","\n","    train_features = np.array(features[:train_end])\n","    valid_features = np.array(features[train_end:])\n","\n","    train_labels = labels[:train_end]\n","    valid_labels = labels[train_end:]\n","\n","    # Convert to arrays\n","    X_train, X_valid = np.array(train_features), np.array(valid_features)\n","\n","    # Using int8 for memory savings\n","    y_train = np.zeros((len(train_labels), num_words), dtype=np.int8)\n","    y_valid = np.zeros((len(valid_labels), num_words), dtype=np.int8)\n","\n","    # One hot encoding of labels\n","    for example_index, word_index in enumerate(train_labels):\n","        y_train[example_index, word_index] = 1\n","\n","    for example_index, word_index in enumerate(valid_labels):\n","        y_valid[example_index, word_index] = 1\n","\n","    # Memory management\n","    import gc\n","    gc.enable()\n","    del features, labels, train_features, valid_features, train_labels, valid_labels\n","    gc.collect()\n","\n","    return X_train, X_valid, y_train, y_valid"],"metadata":{"id":"DMIK7BfKW7VT","executionInfo":{"status":"ok","timestamp":1668126099190,"user_tz":300,"elapsed":263,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"DMIK7BfKW7VT","execution_count":18,"outputs":[]},{"cell_type":"code","source":["X_train, X_valid, y_train, y_valid = create_train_valid(\n","    features, labels, num_words)\n","X_train.shape\n","y_train.shape"],"metadata":{"id":"0txDThkMXJHE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668126100143,"user_tz":300,"elapsed":956,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"outputId":"fcdc1447-b874-42b6-e464-794210da5089"},"id":"0txDThkMXJHE","execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(16556, 50)"]},"metadata":{},"execution_count":19},{"output_type":"execute_result","data":{"text/plain":["(16556, 10047)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["import sys\n","sys.getsizeof(y_train) / 1e9"],"metadata":{"id":"i0iPnUfVXMK7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668126100143,"user_tz":300,"elapsed":5,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"outputId":"f1f77e2b-25c2-4112-f6e4-81fe6323eab6"},"id":"i0iPnUfVXMK7","execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.166338252"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["def check_sizes(gb_min=1):\n","    for x in globals():\n","        size = sys.getsizeof(eval(x)) / 1e9\n","        if size > gb_min:\n","            print(f'Object: {x:10}\\tSize: {size} GB.')\n","\n","\n","check_sizes(gb_min=1)"],"metadata":{"id":"032N2dSi9Chw","executionInfo":{"status":"ok","timestamp":1668126100143,"user_tz":300,"elapsed":3,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"032N2dSi9Chw","execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["# Pre-Trained Embeddings"],"metadata":{"id":"DQPFy4iI99Ow"},"id":"DQPFy4iI99Ow"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pPTsHSUE-Bvo","executionInfo":{"status":"ok","timestamp":1668126116132,"user_tz":300,"elapsed":15992,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"outputId":"3365fa7f-779f-4043-9358-c130d06c8d2b"},"id":"pPTsHSUE-Bvo","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["glove_vectors = '/content/gdrive/My Drive/glove.6B.100d.txt'"],"metadata":{"id":"_SoVGMxH-Gyi","executionInfo":{"status":"ok","timestamp":1668127726606,"user_tz":300,"elapsed":289,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"_SoVGMxH-Gyi","execution_count":25,"outputs":[]},{"cell_type":"code","source":["import os\n","from keras.utils import get_file\n","\n","# Load in unzipped file\n","# glove_vectors = '/home/ubuntu/.keras/datasets/glove.6B.100d.txt'\n","glove = np.loadtxt(glove_vectors, dtype='str', comments=None)\n","glove.shape"],"metadata":{"id":"LcTtcpx09Deq","colab":{"base_uri":"https://localhost:8080/","height":358},"executionInfo":{"status":"error","timestamp":1668127728045,"user_tz":300,"elapsed":249,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}},"outputId":"49b7da31-b4af-4e57-9416-9ce2fd0352f9"},"id":"LcTtcpx09Deq","execution_count":26,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-e38dcfcba3ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load in unzipped file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# glove_vectors = '/home/ubuntu/.keras/datasets/glove.6B.100d.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mglove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'str'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    532\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: /content/gdrive/My Drive/glove.6B.100d.txt not found."]}]},{"cell_type":"code","source":["# separate into the words and the vectors\n","vectors = glove[:, 1:].astype('float')\n","words = glove[:, 0]\n","\n","del glove\n","\n","vectors.shape"],"metadata":{"id":"m6jKH1gM-23x","executionInfo":{"status":"aborted","timestamp":1668126116697,"user_tz":300,"elapsed":8,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"m6jKH1gM-23x","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Next we want to keep only those words that appear in our vocabulary. For words that are in our vocabulary but don't have an embedding, they will be represented as all 0s\n","\n","word_lookup = {word: vector for word, vector in zip(words, vectors)}\n","\n","embedding_matrix = np.zeros((num_words, vectors.shape[1]))\n","\n","not_found = 0\n","\n","for i, word in enumerate(word_idx.keys()):\n","    # Look up the word embedding\n","    vector = word_lookup.get(word, None)\n","\n","    # Record in matrix\n","    if vector is not None:\n","        embedding_matrix[i + 1, :] = vector\n","    else:\n","        not_found += 1\n","\n","print(f'There were {not_found} words without pre-trained embeddings.')"],"metadata":{"id":"oOpFxL5G_9c6","executionInfo":{"status":"aborted","timestamp":1668126116697,"user_tz":300,"elapsed":8,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"oOpFxL5G_9c6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gc\n","gc.enable()\n","del vectors\n","gc.collect()"],"metadata":{"id":"JVYGAp_0AMvB","executionInfo":{"status":"aborted","timestamp":1668126116697,"user_tz":300,"elapsed":8,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"JVYGAp_0AMvB","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normalize and convert nan to 0\n","embedding_matrix = embedding_matrix / \\\n","    np.linalg.norm(embedding_matrix, axis=1).reshape((-1, 1))\n","embedding_matrix = np.nan_to_num(embedding_matrix)"],"metadata":{"id":"JWg79MAMAR-J","executionInfo":{"status":"aborted","timestamp":1668126116697,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"JWg79MAMAR-J","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_closest(query, embedding_matrix, word_idx, idx_word, n=10):\n","    \"\"\"Find closest words to a query word in embeddings\"\"\"\n","\n","    idx = word_idx.get(query, None)\n","    # Handle case where query is not in vocab\n","    if idx is None:\n","        print(f'{query} not found in vocab.')\n","        return\n","    else:\n","        vec = embedding_matrix[idx]\n","        # Handle case where word doesn't have an embedding\n","        if np.all(vec == 0):\n","            print(f'{query} has no pre-trained embedding.')\n","            return\n","        else:\n","            # Calculate distance between vector and all others\n","            dists = np.dot(embedding_matrix, vec)\n","\n","            # Sort indexes in reverse order\n","            idxs = np.argsort(dists)[::-1][:n]\n","            sorted_dists = dists[idxs]\n","            closest = [idx_word[i] for i in idxs]\n","\n","    print(f'Query: {query}\\n')\n","    max_len = max([len(i) for i in closest])\n","    # Print out the word and cosine distances\n","    for word, dist in zip(closest, sorted_dists):\n","        print(f'Word: {word:15} Cosine Similarity: {round(dist, 4)}')"],"metadata":{"id":"rRyQV0h4AUo9","executionInfo":{"status":"aborted","timestamp":1668126116697,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"rRyQV0h4AUo9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["find_closest('the', embedding_matrix, word_idx, idx_word)"],"metadata":{"id":"4ZjEXjZuAVLn","executionInfo":{"status":"aborted","timestamp":1668126116697,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"4ZjEXjZuAVLn","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Build Model"],"metadata":{"id":"mrG9ChNEAhWQ"},"id":"mrG9ChNEAhWQ"},{"cell_type":"code","source":["from keras.models import Sequential, load_model\n","from keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional\n","from keras.optimizers import Adam\n","\n","from keras.utils import plot_model"],"metadata":{"id":"LryZGfunAi2G","executionInfo":{"status":"aborted","timestamp":1668126116698,"user_tz":300,"elapsed":8,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"LryZGfunAi2G","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_word_level_model(num_words,\n","                          embedding_matrix,\n","                          lstm_cells=64,\n","                          trainable=False,\n","                          lstm_layers=1,\n","                          bi_direc=False):\n","    \"\"\"Make a word level recurrent neural network with option for pretrained embeddings\n","       and varying numbers of LSTM cell layers.\"\"\"\n","\n","    model = Sequential()\n","\n","    # Map words to an embedding\n","    if not trainable:\n","        model.add(\n","            Embedding(\n","                input_dim=num_words,\n","                output_dim=embedding_matrix.shape[1],\n","                weights=[embedding_matrix],\n","                trainable=False,\n","                mask_zero=True))\n","        model.add(Masking())\n","    else:\n","        model.add(\n","            Embedding(\n","                input_dim=num_words,\n","                output_dim=embedding_matrix.shape[1],\n","                weights=[embedding_matrix],\n","                trainable=True))\n","\n","    # If want to add multiple LSTM layers\n","    if lstm_layers > 1:\n","        for i in range(lstm_layers - 1):\n","            model.add(\n","                LSTM(\n","                    lstm_cells,\n","                    return_sequences=True,\n","                    dropout=0.1,\n","                    recurrent_dropout=0.1))\n","\n","    # Add final LSTM cell layer\n","    if bi_direc:\n","        model.add(\n","            Bidirectional(\n","                LSTM(\n","                    lstm_cells,\n","                    return_sequences=False,\n","                    dropout=0.1,\n","                    recurrent_dropout=0.1)))\n","    else:\n","        model.add(\n","            LSTM(\n","                lstm_cells,\n","                return_sequences=False,\n","                dropout=0.1,\n","                recurrent_dropout=0.1))\n","    model.add(Dense(128, activation='relu'))\n","    # Dropout for regularization\n","    model.add(Dropout(0.5))\n","\n","    # Output layer\n","    model.add(Dense(num_words, activation='softmax'))\n","\n","    # Compile the model\n","    model.compile(\n","        optimizer='adam',\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy'])\n","    return model\n","\n","\n","model = make_word_level_model(\n","    num_words,\n","    embedding_matrix=embedding_matrix,\n","    lstm_cells=LSTM_CELLS,\n","    trainable=False,\n","    lstm_layers=1)\n","model.summary()"],"metadata":{"id":"GAW1ZP35AwI4","executionInfo":{"status":"aborted","timestamp":1668126116698,"user_tz":300,"elapsed":8,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"GAW1ZP35AwI4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import Image\n","model_name = 'pre-trained-rnn'\n","model_dir = '/content/drive/MyDrive/22FALL9113/'\n","\n","plot_model(model, to_file=f'{model_dir}{model_name}.png', show_shapes=True)\n","\n","Image(f'{model_dir}{model_name}.png')"],"metadata":{"id":"o7xXOOiFA7dX","executionInfo":{"status":"aborted","timestamp":1668126116698,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"o7xXOOiFA7dX","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train Model"],"metadata":{"id":"PMG2ST4sBGTW"},"id":"PMG2ST4sBGTW"},{"cell_type":"code","source":["# Callbacks\n","# Early Stopping: Stop training when validation loss no longer decreases\n","# Model Checkpoint: Save the best model on disk\n","\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","BATCH_SIZE = 2048\n","\n","\n","def make_callbacks(model_name, save=SAVE_MODEL):\n","    \"\"\"Make list of callbacks for training\"\"\"\n","    callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n","\n","    if save:\n","        callbacks.append(\n","            ModelCheckpoint(\n","                f'{model_dir}{model_name}.h5',\n","                save_best_only=True,\n","                save_weights_only=False))\n","    return callbacks\n","\n","\n","callbacks = make_callbacks(model_name)"],"metadata":{"id":"M0HivVVNBIu1","executionInfo":{"status":"aborted","timestamp":1668126116698,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"M0HivVVNBIu1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(\n","    X_train,\n","    y_train,\n","    epochs=EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    verbose=VERBOSE,\n","    callbacks=callbacks,\n","    validation_data=(X_valid, y_valid))"],"metadata":{"id":"ZTUwZU0_Bw6G","executionInfo":{"status":"aborted","timestamp":1668126116698,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"ZTUwZU0_Bw6G","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_and_evaluate(model_name, return_model=False):\n","    \"\"\"Load in a trained model and evaluate with log loss and accuracy\"\"\"\n","\n","    model = load_model(f'{model_dir}{model_name}.h5')\n","    r = model.evaluate(X_valid, y_valid, batch_size=2048, verbose=1)\n","\n","    valid_crossentropy = r[0]\n","    valid_accuracy = r[1]\n","\n","    print(f'Cross Entropy: {round(valid_crossentropy, 4)}')\n","    print(f'Accuracy: {round(100 * valid_accuracy, 2)}%')\n","\n","    if return_model:\n","        return model"],"metadata":{"id":"oC1yh38cB4Fw","executionInfo":{"status":"aborted","timestamp":1668126116698,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"oC1yh38cB4Fw","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = load_and_evaluate(model_name, return_model=True)"],"metadata":{"id":"4d4AaA2qB6RF","executionInfo":{"status":"aborted","timestamp":1668126116698,"user_tz":300,"elapsed":6,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"4d4AaA2qB6RF","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generating Output"],"metadata":{"id":"D6p8uAvmAQUX"},"id":"D6p8uAvmAQUX"},{"cell_type":"code","source":["from IPython.display import HTML\n","\n","\n","def header(text, color='black'):\n","    raw_html = f'\n","{\n","color};\">' + \\\n","        str(text) + ''\n","    return raw_html\n","\n","\n","def box(text):\n","    raw_html = '\n","' \n","\n","'\n","    return raw_html\n","\n","\n","def addContent(old_html, raw_html):\n","    old_html += raw_html\n","    return old_html"],"metadata":{"id":"EbM2tcziARSW","executionInfo":{"status":"aborted","timestamp":1668126116699,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"EbM2tcziARSW","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","\n","def generate_output(model,\n","                    sequences,\n","                    training_length=50,\n","                    new_words=50,\n","                    diversity=1,\n","                    return_output=False,\n","                    n_gen=1):\n","    \"\"\"Generate `new_words` words of output from a trained model and format into HTML.\"\"\"\n","\n","    # Choose a random sequence\n","    seq = random.choice(sequences)\n","\n","    # Choose a random starting point\n","    seed_idx = random.randint(0, len(seq) - training_length - 10)\n","    # Ending index for seed\n","    end_idx = seed_idx + training_length\n","\n","    gen_list = []\n","\n","    for n in range(n_gen):\n","        # Extract the seed sequence\n","        seed = seq[seed_idx:end_idx]\n","        original_sequence = [idx_word[i] for i in seed]\n","        generated = seed[:] + ['#']\n","\n","        # Find the actual entire sequence\n","        actual = generated[:] + seq[end_idx:end_idx + new_words]\n","\n","        # Keep adding new words\n","        for i in range(new_words):\n","\n","            # Make a prediction from the seed\n","            preds = model.predict(np.array(seed).reshape(1, -1))[0].astype(\n","                np.float64)\n","\n","            # Diversify\n","            preds = np.log(preds) / diversity\n","            exp_preds = np.exp(preds)\n","\n","            # Softmax\n","            preds = exp_preds / sum(exp_preds)\n","\n","            # Choose the next word\n","            probas = np.random.multinomial(1, preds, 1)[0]\n","\n","            next_idx = np.argmax(probas)\n","\n","            # New seed adds on old word\n","            seed = seed[1:] + [next_idx]\n","            generated.append(next_idx)\n","\n","        # Showing generated and actual abstract\n","        n = []\n","\n","        for i in generated:\n","            n.append(idx_word.get(i, '< --- >'))\n","\n","        gen_list.append(n)\n","\n","    a = []\n","\n","    for i in actual:\n","        a.append(idx_word.get(i, '< --- >'))\n","\n","    a = a[training_length:]\n","\n","    gen_list = [\n","        gen[training_length:training_length + len(a)] for gen in gen_list\n","    ]\n","\n","    if return_output:\n","        return original_sequence, gen_list, a\n","        \n","    return original_sequence, gen_list, a"],"metadata":{"id":"4CRjnW3hBesr","executionInfo":{"status":"aborted","timestamp":1668126116699,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"4CRjnW3hBesr","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove_spaces(patent):\n","    \"\"\"Remove spaces around punctuation\"\"\"\n","    patent = re.sub(r'\\s+([.,;?])', r'\\1', patent)\n","\n","    return patent\n"],"metadata":{"id":"NviQ70qOCv4Z","executionInfo":{"status":"aborted","timestamp":1668126116699,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"NviQ70qOCv4Z","execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed, gen, a = generate_output(model, sequences,\n","                                              TRAINING_LENGTH)"],"metadata":{"id":"YrNZVP1uCCwB","executionInfo":{"status":"aborted","timestamp":1668126116699,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"YrNZVP1uCCwB","execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed = remove_spaces(' '.join(seed))\n","gen = remove_spaces(' '.join(gen[0]))\n","a = remove_spaces(' '.join(a))\n"],"metadata":{"id":"jV_eWfGCCLSa","executionInfo":{"status":"aborted","timestamp":1668126116699,"user_tz":300,"elapsed":7,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"jV_eWfGCCLSa","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Seed is :\" + seed)\n","print(\"Generate is :\" + gen)\n","print(\"Actual is :\" +a)"],"metadata":{"id":"ypTq2aF7Dgil","executionInfo":{"status":"aborted","timestamp":1668126116699,"user_tz":300,"elapsed":6,"user":{"displayName":"Trishita Singh","userId":"17463607412823158907"}}},"id":"ypTq2aF7Dgil","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[{"file_id":"1EfvAdLFs6RjLxW5UScZ_yEEoMOCvyZJD","timestamp":1667872628639}]}},"nbformat":4,"nbformat_minor":5}